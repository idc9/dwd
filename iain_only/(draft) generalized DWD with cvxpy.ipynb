{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator  # , TransformerMixin, ClassifierMixin\n",
    "from sklearn.linear_model.base import LinearClassifierMixin\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V_(u, q=1):\n",
    "    if u <= q / (q + 1.0):\n",
    "        return 1 - u\n",
    "    else:\n",
    "        return (1.0 / u ** q) * (q ** q / (q + 1) ** (q + 1))\n",
    "\n",
    "def V_grad_(u, q=1):\n",
    "    # TODO: check\n",
    "    if u <= q / (q + 1.0):\n",
    "        return -1\n",
    "    else:\n",
    "        return (- q / u ** (q + 1)) * (q ** q / (q + 1) ** (q + 1))\n",
    "\n",
    "V = np.vectorize(V_, excluded=['q'])\n",
    "V_grad = np.vectorize(V_grad_, excluded=['q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1ebc8fd0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "U = np.linspace(-10, 10, 100)\n",
    "plt.plot(V_grad(U, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxpy.atoms.elementwise.elementwise import Elementwise\n",
    "\n",
    "class V_fun(Elementwise):\n",
    "    \"\"\"Elementwise :math:`e^{x}`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, q=1):\n",
    "        self.q = q\n",
    "        super(V_fun, self).__init__(x)\n",
    "\n",
    "    @Elementwise.numpy_numeric\n",
    "    def numeric(self, values):\n",
    "        return V(u=values[0], q=self.q)\n",
    "\n",
    "    def sign_from_args(self):\n",
    "        \"\"\"Returns sign (is positive, is negative) of the expression.\n",
    "        \"\"\"\n",
    "        # Always positive.\n",
    "        return (True, False)\n",
    "\n",
    "    def is_atom_convex(self):\n",
    "        \"\"\"Is the atom convex?\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def is_atom_concave(self):\n",
    "        \"\"\"Is the atom concave?\n",
    "        \"\"\"\n",
    "        return False\n",
    "\n",
    "    def is_atom_log_log_convex(self):\n",
    "        \"\"\"Is the atom log-log convex?\n",
    "        \"\"\"\n",
    "        # TODO: check\n",
    "        return True\n",
    "\n",
    "    def is_atom_log_log_concave(self):\n",
    "        \"\"\"Is the atom log-log concave?\n",
    "        \"\"\"\n",
    "        return False\n",
    "\n",
    "    def is_incr(self, idx):\n",
    "        \"\"\"Is the composition non-decreasing in argument idx?\n",
    "        \"\"\"\n",
    "        return False\n",
    "\n",
    "    def is_decr(self, idx):\n",
    "        \"\"\"Is the composition non-increasing in argument idx?\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def _grad(self, values):\n",
    "        \"\"\"Gives the (sub/super)gradient of the atom w.r.t. each argument.\n",
    "        Matrix expressions are vectorized, so the gradient is a matrix.\n",
    "        Args:\n",
    "            values: A list of numeric values for the arguments.\n",
    "        Returns:\n",
    "            A list of SciPy CSC sparse matrices or None.\n",
    "        \"\"\"\n",
    "        rows = self.args[0].size\n",
    "        cols = self.size\n",
    "        grad_vals = V_grad(values[0], q=self.q)\n",
    "        return [exp.elemwise_grad_to_diag(grad_vals, rows, cols)]\n",
    "    \n",
    "    def get_data(self):\n",
    "        return [self.q]\n",
    "\n",
    "    def copy(self, args=None, id_objects={}):\n",
    "        \"\"\"Returns a shallow copy of the power atom.\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : list, optional\n",
    "            The arguments to reconstruct the atom. If args=None, use the\n",
    "            current args of the atom.\n",
    "        Returns\n",
    "        -------\n",
    "        power atom\n",
    "        \"\"\"\n",
    "        if args is None:\n",
    "            args = self.args\n",
    "        # Avoid calling __init__() directly as we do not have p and max_denom.\n",
    "        copy = type(self).__new__(type(self))\n",
    "        # Emulate __init__()\n",
    "        copy.q = self.get_data()[0]\n",
    "        super(type(self), copy).__init__(*args)\n",
    "        return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def solve_gen_dwd(X, y, lambd=1.0, q=1, sample_weight=None, solver_kws={}):\n",
    "    \"\"\"\n",
    "    Solves distance weighted discrimination optimization problem.\n",
    "\n",
    "    Solves problem (2.7) from https://arxiv.org/pdf/1508.05913.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: (n_samples, n_features)\n",
    "\n",
    "    y: (n_samples, )\n",
    "\n",
    "    C: float\n",
    "        Strictly positive tuning parameter.\n",
    "\n",
    "    sample_weight: None, (n_samples, )\n",
    "        Weights for samples.\n",
    "\n",
    "    solver_kws: dict\n",
    "        Keyword arguments to cp.solve\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    beta, intercept, problem\n",
    "\n",
    "    beta: (n_features, )\n",
    "        DWD normal vector.\n",
    "\n",
    "    intercept: float\n",
    "        DWD intercept.\n",
    "\n",
    "    problem: cp.Problem\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    y = np.array(y).reshape(-1)\n",
    "    labels = np.unique(y)\n",
    "    # only implemented for binary classification\n",
    "    assert len(labels) == 2\n",
    "\n",
    "    # make y +/- 1\n",
    "    # np.unique(y)[1] is the positive class\n",
    "    y_pm1 = np.ones(n_samples)\n",
    "    y_pm1[y == labels[0]] = -1\n",
    "    y = y_pm1\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # problem data\n",
    "    X = cp.Parameter(shape=X.shape, value=X)\n",
    "    y = cp.Parameter(shape=y.shape, value=y)\n",
    "    lambd = cp.Parameter(value=lambd, nonneg=True)\n",
    "    q = cp.Parameter(value=q, nonneg=True)\n",
    "\n",
    "    # optimization variables\n",
    "    beta = cp.Variable(shape=n_features)\n",
    "    intercept = cp.Variable()\n",
    "\n",
    "    # objective funtion\n",
    "    d = cp.multiply(y, X @ beta + intercept)\n",
    "    # objective = sum(V_fun(d[i], q=q) for i in range(n_samples))\n",
    "    # objective = sum(V_fun(d[i]) for i in range(n_samples))\n",
    "    objective = sum(cp.exp(d[i]) for i in range(n_samples))\n",
    "\n",
    "    # solve problem\n",
    "    problem = cp.Problem(cp.Minimize(objective))\n",
    "\n",
    "    problem.solve(**solver_kws)\n",
    "\n",
    "    return beta.value, intercept.value, problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_features': 2,\n",
    "          'n_redundant': 0,\n",
    "          'n_classes': 2,\n",
    "          'n_clusters_per_class': 1,\n",
    "          'flip_y': .1,\n",
    "          'class_sep': 1.0}\n",
    "\n",
    "X, y = make_classification(n_samples=200, random_state=0, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.8888378,  0.0731408]),\n",
       " array(-0.07046917),\n",
       " Problem(Minimize(Expression(CONVEX, NONNEGATIVE, ())), []))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_gen_dwd(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mv_gmm] *",
   "language": "python",
   "name": "conda-env-mv_gmm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
